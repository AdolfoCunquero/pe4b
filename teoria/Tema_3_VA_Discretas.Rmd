---
title: "Tema 3 - Variables Aleatorias discretas"
author: "Ricardo Alberich, Juan Gabriel Gomila y  Arnau Mir"
date: 
output: 
  ioslides_presentation: 
    css: Mery_style.css
    keep_md: no
    logo: Images/matriz_mov.gif
    widescreen: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Introducción a las variables aleatorias


## Introducción

* Hasta ahora nuestros sucesos han sido de varios tipos: $\{C,+\}$ en
la moneda, nombres de periódicos, ángulos en una ruleta, número de
veces que sale cara en el lanzamiento de una moneda etc\ldots.
* Necesitamos estandarizar de alguna manera todos estos sucesos. Una
solución es asignar a cada suceso un cierto conjunto de
números reales, es decir, convertir todos los sucesos en
*sucesos de números reales* para trabajar con ellos de forma
unificada.
* Para conseguirlo utilizaremos  unas funciones que
transformen los elementos del espacio muestral en números; esta funciones son las
variables aleatorias.


## Definición de variable aleatoria
 Comenzaremos dando una definición poco rigurosa, pero suficiente, de  variable aleatoria.

<l class="definition"> Variable Aleatoria (definición práctica) </l>


Una variable aleatoria (v.a.) es una aplicación que toma valores numéricos determinados por el resultado de un experimento aleatorio

<div class="observ">
**Notación**:
</div>
* Normalmente representaremos las v.a. por letras mayúsculas $X,Y,Z\ldots$
* Los valores que "*toman*" las v.a. los representaremos por letras minúsculas (las mismas en principio) $x,y,z\ldots$


## Ejemplo

<div class="example">
**Ejemplo**

Lanzamos un dado convencional de parchís el espacio muestral del experimento es

$$\Omega=\{1,2, 3, 4,  5, 6\}.$$


</div>

<div class="example-sol">
Una v.a $X:\Omega\to\mathbb{R}$
sobre este espacio queda definida por 

\begin{equation*}
\begin{split}
X(1)&=1,X(2)=2,X(3)=3,\\
X(4)&=4,X(5)=5,X(6)=6.
\end{split}
\end{equation*}

* Ahora el suceso $A=\{2, 4, 6\}$, es decir "salir
número par", es equivalente a $\{X=2,X=4,X=6\}$.
* El suceso $B=\{1,2,3\}$, es decir "salir un número
inferior o igual a $3$" es  en términos de la v.a. $\{X=1,X=2,X=3\}$ o también $\{X\leq
3\}$.

</div>

## Ejemplo

<div class="example">
**Ejemplo**

Consideremos el experimento lanzar una anilla al cuello de una botella. Si acertamos a
ensartar la anilla en la botella el resultado del experimento es **éxito** y
**fracaso** en caso contrario. 
</div>

<div class="example-sol">
El espacio muestral asociado a este experimento será
$\Omega=\{\mbox{éxito, fracaso}\}$. Construyamos la siguiente variable aleatoria:

$$X:\{\mbox{éxito, fracaso}\}\to\mathbb{R}$$

definida por 

$$X(\mbox{éxito})=1 \mbox{ y } X(\mbox{fracaso})=0.$$

</div>


## Tipos de variables aleatorias

Hay dos tipos fundamentales de variables aleatorias, las discretas y las continuas.

Damos a continuación una definición informal.

<l class="definition">Variables Aleatorias Discretas y Continuas </l>

* Una variable aleatoria es **discreta** si sólo puede tomar una cantidad numerable de valores con probabilidad positiva.
* Las variables aleatorias **continuas**  toman  valores en intervalos.
* También existen las variables aleatorias **mixtas**; con una parte discreta y otra continua.



## Ejemplo

<div class="example">
**Ejemplo**

Son variables *aleatorias discretas*:
      
*  Número de artículos defectuosos en un cargamento.
*  Número de clientes que llegan a una ventanilla de un banco en una hora.
*  Número de errores detectados en las cuentas de una compañía.
*  Número de reclamaciones de una póliza de un seguro médico.
      
Son variables *aleatorias continuas*:
      
* Renta anual de una familia.
* Cantidad de petróleo importado por un país.
* Variación del precio de las acciones de una compañía de telecomunicaciones.
* Porcentaje de impurezas en un lote de productos químicos.
      
</div>


# Variables aleatorias discretas


## Función de probabilidad para variables discretas

<l class="definition"> **Función de Probabilidad**</l>

La **función de probabilidad** (*probability mass function* o incluso abusando de notación *probability density function*)
de una variable aleatoria discreta $X$ a la que denotaremos por $P_{X}(x)$ está definida por

$$P_{X}(x)=P(X=x),$$

es decir la probabilidad de que $X$ tome el valor $x$.

Si $X$ no asume ese valor $x$, entonces
$P_{X}(x)=0$.
</div>

## Función  de probabilidad discreta

<l class="definition"> **Dominio de una variable aleatoria discreta** </l> 

El conjunto $$D_X=\{ x\in\mathbb{R} \mid P_X(x)>0\}$$ recibe el nombre de
**dominio** de la v.a. y son los valores posibles de esta variable. 

En el caso discreto lo más habitual es que $X(\Omega)=D_X$.

## Propiedades de la función de probabilidad.

<l class="prop">Propiedades básicas de la función de probabilidad </l>

Sea $X$ una v.a. discreta $X:\Omega:\to\mathbb{R}$ con dominio $D_X$. Su función de probabilidad $P_{X}$ verifica las siguientes propiedades:

* $0\leq P_{X}(x)\leq 1$ para todo $x\in\mathbb{R},$
* $\sum\limits_{x\in D_X} P_{X}(x)=1.$


## Función de distribución de variables aleatorias

<l class="definition">Distribución de Probabilidad</l>

La función de *distribución de probabilidad* (acumulada) de la v.a. $X$ (de cualquier tipo;
discreta o continua) $F_{X}(x)$ representa la probabilidad de que $X$  tome un menor o igual que  $x$, es decir,

$$F_{X}(x)=P(X\leq x).$$

Esta función también se denomina función de **distribución de
probabilidad o simplemente función de distribución** de una v.a., y en inglés
*cumulative distribution function* por lo que se abrevia con el acrónimo `cdf`.



## Propiedades


<l class="definition">Propiedades de la Función de Distribución</l>

Sea $X$ una v.a. y $F_{X}$ su función
de distribución:

1. $P(X>x)=1-P(X\leq x)=1-F_{X}(x).$
2.  Sea a y b tales que $a<b$, $P(a<X\leq b)=P(X\leq b)-P(X\leq a)=F_{X}(b)-F_{X}(a).$


## Propiedades

<l class="definition"> **Propiedades de la Función de Distribución**</l>

Sea $F_{X}$ la función de distribución  de una  v.a. $X$ entonces:
 
* $0\leq F_{X}(x)\leq 1$.
* La función $F_{X}$ es no decreciente.
* La función $F_{X}$ es continua por la derecha.
* Si denotamos por $F_X(x_0^{-})=\displaystyle \lim_{x\to x_0^{-}} F(x)$,
entonces se cumple que $P(X< x_0)=F_X(x_0^{-})$ y que $P(X=x_0)=F_X(x_0)-F_X(x_0^{-})$.

## Propiedades

<l class="definition"> **Propiedades de la Función de Distribución**</l>

* Se cumple que $\displaystyle \lim_{x\to\infty} F_{X}(x)=1$; $\displaystyle \lim_{x\to-\infty}F_{X}(x)=0$.
* Toda función $F$ verificando las propiedades anteriores es función de distribución de alguna v.a. $X$.
* $P(X>x)=1-F_{X}(x)$.
* Dados $a,b\in \mathbb{R}$ con $a<b$ $$P(a<X\leq b)=F_{X}(b)-F_{X}(a).$$


## Propiedades de la función de distribución

<l class="prop">Propiedad</l>

Sea $X$ una variable con función de distribución $F_{X}$ entonces:
 
* $0\leq F_{X}(x)\leq 1$ para todo $x$,
* Si $x<x'$, entonces $$F_{X}(x)\leq F_{X}(x').$$
Es una función creciente,es decir, no necesariamente estrictamente creciente.
* $\displaystyle \lim_{x\to -\infty}F_{X}(x)=0$ y $\displaystyle \lim_{x\to +\infty}F_{X}(x)=1.$
* Es continua por la derecha $\displaystyle \lim_{x\to x_0^{+}}F_{X}(x)=F_{X}(x_0)$.
  

# Valores esperados  o esperanza

## Esperanza  de un variable aleatoria discreta


<l class="definition">Esperanza de una variable aleatoria discreta </l>

El valor **esperado o esperanza** (*expected value* en inglés) $E(X)$ de una v.a. discreta $X$, se define como

$$
E(X)=\sum_{x\in X(\Omega)} x\cdot P_{X}(x).
$$


En ocasiones se denomina **media** (*mean* en inglés, *mitjana* en catalán) poblacional o simplemente media y muy frecuentemente se la denota $\mu_{X}=E(X)$ o simplemente $\mu=E(X)$.


## Esperanzas de funciones de variables aleatorias discretas

<l class="definition"> Esperanzas de funciones de variables aleatorias discretas</l>

Sea $X$ una v.a. discreta con función de probabilidad $P_{X}$ y de distribución
$F_{X}$. Entonces el *valor esperado de una función* $g(x)$ es:

$$E(g(X))=\sum_{x}g(x) \cdot  P_{X}(x).$$


## Propiedades de los valores esperados


<l class="prop"> Propiedades</l>
 
* $E(k)=k$ para cualquier constante $k$.
* Si $a\leq X\leq b$ entonces $a\leq E(X)\leq b$.
* Si $X$ es una v.a. discreta que toma valores enteros no negativos entonces
$E(X)=\sum_{x=0}^{+\infty}(1- F_X(x)).$


# Varianza y desviación típica


## Varianza y desviación típica


<l class="definition"> Varianza </l>

Sea $X$ una v.a. Llamaremos **varianza** de $X$ a

$$Var(X)=E((X-E(X))^2).$$

Por lo tanto, la varianza es el momento central de orden $2$.

De forma frecuente se utiliza la notación $$\sigma_{X}^2=Var(X).$$
    
A la raíz cuadrada positiva de la varianza
$$\sigma_{X}=+\sqrt{Var(X)}.$$
   
se la denomina desviación típica  o estándar de $X$.




## Propiedades de la varianza
 
<l class="prop">Propiedad </l>

* Si $X$ es una v.a. discreta con función de probabilidad $P_X$ su varianza es 
 $$\sigma_{X}^2=Var(X)=E((X-E(X))^2)=\sum_{x}(x-E(X))^2\dot  P_{X}(x).$$
* Sea $X$ una v.a.
 $$Var(X)=E(X^2)-(E(X))^2=\sum_{x} x^2\cdot  P_{X}(X)-(E(X))^2$$
  


## Propiedades de la varianza
 
 
<l class="prop"> **Propiedades de la varianza**</l>

* $Var(X)\geq 0$.
* $Var(cte)=E(cte^2)-(E(cte))^2= cte^2 - cte^2=0$.
* El mínimo de $E((X-C)^2)$ se alcanza cuando $C=E(X)$ y es $Var(X)$. Esta propiedad es una de las que hace útil a la varianza como medida de dispersión.


# Esperanza y varianza de transformaciones lineales.


## Transformaciones lineales. 

<l class="definition"> Transformación lineal </l>

Un **cambio de variable lineal** o **transformación lineal** de una v.a. $X$ es otra v.a. $Y= a+ b\cdot  X$  donde $a,b\in\mathbb{R}$.

<l class="prop">Esperanza de una transformación lineal</l>

Sea $X$ una v.a. con $E(X)=\mu_{X}$ y $Var(X)=\sigma_{X}^2$ y $a,b\in\mathbb{R}$.
Entonces si $Y=a+b\cdot  X$:
 
* $E(Y)=E(a + b X)=a+ b E(X)= a + b \cdot \mu_{X}$.
* $Var(Y)=Var(a+bX)=b^2 Var(X)= b^2\cdot  \sigma_{X}^2$.
* $\sigma_{Y}=\sqrt{Var(Y)}=\sqrt{b^2 Var(X)}=|b| \cdot \sigma_{X}$.




# Distribuciones notables

## Variable aleatoria Bernoulli


$X$  Bernoulli | $Ber(p)$
----------:|:--------
$D_X=$ | $\{0,1\}$
$P_X(x)=P(X=x)=$ |  $\left\{\begin{array}{ll} q & \mbox{si } x=0\\ p & \mbox{si } x=1\\0 & \mbox{en otro caso}\end{array}\right.$ 
$F_X(x)=P(X\leq X)=$ | $\left\{\begin{array}{ll} 0 & \mbox{ si } x<0\\q & \mbox{ si } 0\leq x<1\\1 & \mbox{ si } 1\leq x \end{array}\right.$
$E(X)=p$ | $Var(X)=p\cdot q$

## Distribución Bernoulli. 

```{r fig.align='center',echo=FALSE}
par(mfrow=c(1,2))
plot(x=c(0,1),y=dbinom(c(0,1),size=1,prob=0.25),
     ylim=c(0,1),xlim=c(-1,2),xlab="x",
     main="Función de probabilidad\n Ber(p=0.25)")
lines(x=c(0,0,1,1),y=c(0,0.75,0,0.25), type = "h", lty = 2,col="blue")
curve(pbinom(x,size=1,prob=0.25),
      xlim=c(-1,2),col="blue",
      main="Función de distribución\n Ber(p=0.25)")
par(mfrow=c(1,1))
```

## Variable aleatoria binomial $B(n,p)$

$X$ binomial | $B(n,p)$ 
-------------:|:--------
$D_X=$ |  $\{0,1,\ldots n\}$ 
$P_X(x)=P(X=x)=$ |$\left\{\begin{array}{ll}{n\choose x}\cdot  p^x\cdot  (1-p)^{n-x} & \mbox{ si } x=0,1,\ldots,n\\0  & \mbox{ en otro caso.}\end{array}\right.$
$F_X(x)=P(X\leq X)=$ | no tiene fórmula 
$E(X)=$ |  $n\cdot p$
$Var(X)=$ | $n\cdot p \cdot (1-p)$


## Gráficas de la distribución binomial

El siguiente código de R dibuja las función de probabilidad y la de distribución de una  $B(n=10,p=0.25)$


```{r fig.align='center',echo=FALSE}
par(mfrow=c(1,2))
aux=rep(0,22)
aux[seq(2,22,2)]=dbinom(c(0:10),size=10,prob=0.25)
plot(x=c(0:10),y=dbinom(c(0:10),size=10,prob=0.25),
  ylim=c(0,1),xlim=c(-1,11),xlab="x",
  main="Función de probabilidad\n B(n=10,p=0.25)")
lines(x=rep(0:10,each=2),y=aux, type = "h", lty = 2,col="blue")
curve(pbinom(x,size=10,prob=0.25),
  xlim=c(-1,11),col="blue",
  main="Función de distribución\n B(n=10,p=0.25)")
par(mfrow=c(1,1))
```

## Resumen $Ge(p)$

$X=$ Geométrica (empieza en $0$)  | número de fracasos  para conseguir el primer éxito
------:|:-----
$D_X=$ | $\{0,1,\ldots n,\ldots\}$ 
$P_X(x)=P(X=x)=$ |$\left\{\begin{array}{ll}(1-p)^{x}\cdot p & \mbox{ si } x=0,1,2,\ldots \\0  & \mbox{ en otro caso.}\end{array}\right.$
$F_X(x)=P(X\leq X)=$ | $\left\{\begin{array}{ll} 0 & \mbox{ si } x<0\\
  1- (1-p)^{k+1} & \mbox{ si } \left\{ \begin{array}{l}k\leq x< k+1\\\mbox{para } k=0,1,2,\ldots\end{array}
    \right.\end{array}\right.$ 
$E(X)=\frac{1-p}{p}$ | $Var(X)=\frac{1-p}{p^2}$

## Propiedad de la falta de memoria

<l class="prop"> Propiedad de la falta  de memoria </l>

Sea $X$ una v.a. discreta con dominio $D_X=\{0,1,2,\ldots\}$, con $P(X=0)=p$.

Entonces $X$ sigue una ley $Ge(p)$ si, y sólo si,
$$
P\left(X> k+j\big| X\geq j\right)=P(X> k)
$$
para todo $k,j=0,1,2,3\ldots$.

##  Gráficos


```{r graficos22, fig.align='center',echo=FALSE}
  par(mfrow=c(1,2))
  p=0.25
  n=30
  aux=rep(0,(n+1)*2)
  aux[seq(2,(n+1)*2,2)]=dgeom(c(0:n),prob=p)
  plot(x=c(0:n),y=dgeom(c(0:n),prob=p),
       ylim=c(0,1),xlim=c(-1,n+1),xlab="x",
       main=paste0(c("Función de probabilidad\n Ge(p=",p,")"),collapse = ""))
  lines(x=rep(0:n,each=2),y=aux, type = "h", lty = 2,col="blue")
  curve(pgeom(x,prob=p),
        xlim=c(-1,n+1),col="blue",
        main=paste0(c("Función de distribución\n Ge(p=",p,")"),collapse = ""))
  par(mfrow=c(1,1))
```


## Distribución  Poisson  $X\equiv Po(\lambda)$

$X$ Poisson |  $\lambda$
-------:|:-------
$D_X=$|  $\{0,1,\ldots \}$ 
$P_X(x)=P(X=x)=$ | $\left\{\begin{array}{ll}  \frac{\lambda^x}{x!}e^{-\lambda} & \mbox{ si } x=0,1,\ldots\\ 0  & \mbox{ en otro caso.}\end{array}\right.$
$F_X(x)=P(X\leq X)=$ |  $\begin{array}{l}\left\{\begin{array}{ll} 0 & \mbox{si } x<0\\\displaystyle\sum_{i=0}^{k} P(X=i)= \displaystyle\sum_{i=0}^{k} \frac{\lambda^i}{i!}\cdot e^{-\lambda} & \mbox{si  }\left\{\begin{array}{l}k\leq x< k+1\\k=0,1,2,\ldots\end{array}\right.\end{array}\right.
\\
\end{array}$     
$E(X)=\lambda$ | $Var(X)=\lambda$

## Gráficos  de la distribución Poisson

```{r graficosPOISON, fig.align='center',echo=FALSE}
lambda=20
par(mfrow=c(1,2))
n=qpois(0.99,lambda=lambda)
aux=rep(0,(n+1)*2)
aux[seq(2,(n+1)*2,2)]=dpois(c(0:n),lambda=lambda)
ymax=max(ppois(0:n,lambda=lambda))
plot(x=c(0:n),y=dpois(c(0:n),lambda=lambda),
     ylim=c(0,ymax),xlim=c(-1,n+1),xlab="x",ylab="Función de probabilidad",
     main=paste0(c("Función de probabilidad\n  Po(lambda=",lambda,")"),collapse = ""))
lines(x=rep(0:n,each=2),y=aux,pch=21, type = "h", lty = 2,col="blue")
curve(ppois(x,lambda=lambda),
      xlim=c(-1,n+1),col="blue",ylab="Función de Distribución",
      main=paste0(c("Función de distribución \n Po(lambda=",lambda,")"),collapse = ""))
par(mfrow=c(1,1))
```

## Distribución hipergeométrica $H(m,n,k)$.

$X=$número de éxitos en $k$ intentos sin reposición de entre $m$ casos de éxito y $n$ de fracaso.| $H(m,n,k)$
------:|:------
$D_X$= | $\left\{x\in\mathbf{N}\mid \max\{0,k-n\}\leq  x \leq \min\{m,k\}\right\}$
$P_X(x)=P(X=x)=$ | $\left\{
\begin{array}{ll}
\frac{\binom{m}{x}\cdot \binom{n}{k-x}}{\binom{m+n}{k}}, & \mbox{ si }
\max\{0,k-n\}\leq x \leq \min\{m,k\}, \\
0,  & \mbox{en otro caso.}\end{array}\right.$
$F_X(x)=P(X\leq x)$ | No tiene una expresión explícita.
$E(X)=\frac{k\cdot m}{m+n}$   | $Var(X)=k\cdot\frac{m}{m+n}\cdot\left(1-\frac{m}{m+n}\right) \cdot\frac{m+n-k}{m+n-1}$

## Gráficas

```{r fig.align='center',echo=FALSE}
par(mfrow=c(1,2))
m=15
n=10
k=3
a=max(c(0,k-n))
b=min(c(m,k))
l=b-a+1
aux=rep(0,2*l)
aux[seq(2,2*l,2)]=dhyper(c(a:b),m=m,n=n,k=k)
x=a:b
plot(x,y=dhyper(x,m=m,n=n,k=k),
  ylim=c(0,0.6),xlim=c(a-1,b+1),xlab="x",
  main=paste0("Función de probabilidad\n H(m=",m,", n=",n,", k=",k,")"))
lines(x=rep(a:b,each=2),y=aux, type = "h", lty = 2,col="blue")
curve(phyper(x,m=m,n=n,k=k),
  xlim=c(a-1,b+1),col="blue",
  main=paste0("Función de distribución\n H(m=",m,", n=",n,", k=",k,")"))
par(mfrow=c(1,1))
```

# Variables aleatorias bidimensionales discretas




## Dos variables aleatorias pe4b

RESUMIR 176-180 CON EJEMPLO INCLUIDO HASTA MEDIA Y VARIANZA CONDICIONAL


## Variables aleatorias bidimensionales discretas. Introducción

<l class="definition">Definición de variable aleatoria bidimensional discreta:</l>
Sea $(X,Y)$ una **variable aleatoria bidimensional**. Diremos que es discreta cuando su conjunto de valores en $\mathbb{R}^2$, $(X,Y)(\Omega)$ es un conjunto finito o numerable. 

En la mayoría de los casos, dicho conjunto será un subconjunto de los enteros naturales.

## Función de probabilidad conjunta
<l class="definition">Definición de función de probabilidad conjunta:</l>
Dada una **variable aleatoria bidimensional discreta** $(X,Y)$ con $(X,Y)(\Omega)=\{(x_i,y_j),\ i=1,2,\ldots,\ j=1,2,\ldots,\}$, definimos la función de probabilidad discreta $P_{XY}$ para un valor $(x,y)\in\mathbb{R}^2$ de la siguiente forma:
$$
\begin{array}{rl}
P_{XY}: \mathbb{R}^2 & \longrightarrow [0,1]\\
(x,y) & \longrightarrow P_{XY}(x,y)=P(X= x,\ Y= y).
\end{array}
$$


Llamaremnos dominio de la variable conjunta a $D_{XY}=\{(x,y)\in \mathbb{R}^2 | P_{XY}(x,y)=P(X= x,\ Y= y)>0}$.

Es¡decir es el conjunto de valores posibles que toma la v.a. $(X,Y)$.

## Función de probabilidad conjunta

Por tanto, de cara a calcular $P_{XY}$ basta calcular $P_{XY}(x_i,y_j)$ para $(x_i,y_j)\in D_{XY}$:

<div class="center">
| $X/Y$| $y_1$    | $y_2$  | $\ldots$ | $y_N$ |
|----|----|----|----|----|
| $x_1$| $P_{XY}(x_1,y_1)$ | $P_{XY}(x_1,y_2)$ | $\ldots$ | $P_{XY}(x_1,y_N)$|
| $x_2$| $P_{XY}(x_2,y_1)$ | $P_{XY}(x_2,y_2)$ | $\ldots$ | $P_{XY}(x_2,y_N)$|
| $\vdots$ |$\vdots$ |$\vdots$ |$\vdots$ |$\vdots$ |
| $x_M$| $P_{XY}(x_M,y_1)$ | $P_{XY}(x_M,y_2)$ | $\ldots$ | $P_{XY}(x_M,y_N)$|
</div>





## Propiedades de la función de probabilidad conjunta

Sea $(X,Y)$ una **variable aleatoria bidimensional discreta** con dominio $D_{XY}=\{(x_i,y_j)\, i=1,2,\ldots,\ j=1,2,\ldots\}$. Entonces su **función de probabilidad conjunta** verifica las propiedades siguientes:

La suma de todos los valores de la **función de probabilidad conjunta** sobre el conjunto de valores siempre vale 1: $$\sum_{i}\sum_j P_{XY}(x_i,y_j)=1.$$


## Propiedades de la función de probabilidad conjunta

Sea $B$ un subconjunto cualquiera del dominio $D_{XY}$. El valor de la probabilidad $P((X,Y)\in B)$ se puede calcular de la forma siguiente:
$$
P((X,Y)\in B) =\sum_{(x_i,y_j)\in B} P_{XY}(x_i,y_j).
$$
O sea, la probabilidad de que la variable bidimensional tome valores en $B$ es igual a la suma de todos aquellos valores de la función de probabilidad conjunta que están en $B$.

## Propiedades de la función de probabilidad conjunta

En particular, tenemos la relación siguiente que relaciona la **función de distribución conjunta** con la **función de probabilidad conjunta**:
$$
F_{XY}(x,y)=\sum_{x_i\leq x, y_j\leq y} P_{XY}(x_i,y_j).
$$
Dicha expresión se deduce de la expresión anterior considerando $B=(-\infty,x]\times (-\infty,y]$.



## Variables aleatorias marginales
Consideremos una variable aleatoria **bidimensional discreta $(X,Y)$** con **función de probabilidad conjunta** $P_{XY}(x_i,y_j)$, con $(x_i,y_j)\in D_{XY}$, $i=1,2,\ldots$, $j=1,2,\ldots$.

La tabla de la **función de probabilidad conjunta** contiene suficiente información para obtener las **funciones de probabilidad** de las variables $X$ e $Y$. 

Dichas variables $X$ e $Y$ se denominan **distribuciones marginales** y sus correspondientes **funciones de probabilidad**, **funciones de probabilidad marginales** $P_X$ de la variable $X$ y $P_Y$ de la variable $Y$.

Veamos cómo obtener $P_X$ y $P_Y$ a partir de la tabla $P_{XY}$.

## Variables aleatorias marginales
<l class="prop">Proposición. Expresión de las funciones de probabilidad marginales. </l>
Sea $(X,Y)$ una variable aleatoria **bidimensional discreta** con **función de probabilidad conjunta** $P_{XY}(x_i,y_j)$, con $(x_i,y_j)\in (X,Y)(\Omega)$, $i=1,2,\ldots$, $j=1,2,\ldots$.

Las **funciones de probabilidad marginales** $P_X(x_i)$ y $P_Y(y_j)$ se calculan usando las expresiones siguientes:
$$
\begin{array}{rl}
P_X(x_i)  & = \sum_{j=1} P_{XY}(x_i,y_j),\  i=1,2,\ldots,\\ P_Y(y_j) &  = \sum_{i=1} P_{XY}(x_i,y_j),\ \ j=1,2,\ldots
\end{array}
$$

## Variables aleatorias marginales


Podemos representar  $P_{XY}$ como una tabla bidimensional donde en la primera fila están los valores de la variable $Y$ ($y_1,y_2,\ldots$) y en la primera columna están los valores de la variable $X$ ($x_1,x_2,\ldots$), para obtener la **función de probabilidad marginal** de la variable $X$ en el valor $x_i$, $P_X(x_i)$, hay que sumar todos los valores de $P_{XY}(x_i,y_j)$ correspondientes a la fila $i$-ésima y para obtener la **función de probabilidad marginal** de la variable $Y$ en el valor $y_j$, $P_Y(y_j)$, hay que sumar todos los valores de $P_{XY}(x_i,y_j)$ correspondientes a la columna $j$-ésima.

## Esperanzas y varianza de las distribuciones  marginales


$$E(X)=\sum_{x\in D_X} x\cdot P(X=x)$$
$$E(Y)=\sum_{x\in D_Y} y\cdot P(Y=y)$$
$$Var(X)=E(X-E(X))=E(X)-E(X)^2;\quad Var(Y)=E(Y-E(Y))=E(Y)-E(Y)^2$$
## Distibuciones condicionales


$$P(X=x|Y=y)=\frac{P_{XY}(x,y)}{P_Y(y)}=\frac{P(X=x,Y=y)}{P(Y=y)}$$
$$P(Y=y|X=x)=\frac{P_{XY}(x,y)}{P_X(x)}=\frac{P(X=x,Y=y)}{P(X=x)}$$

## Esperanzas condicionales

$$E(X/Y=y)=\sum_{x\in D_X} x\cdot P(X=x/Y=y)$$

$$E(Y/X=x)=\sum_{y\in D_Y} y\cdot P(Y=y|X=x))$$



## Covarianza y correlación pe4b

RESUMIR FUSILAR PÁGINA 182. EJEMPLO DE LA PÁGINA 183 + RESUMEN 184 Y 185